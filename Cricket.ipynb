{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### I have developed the program to predicted answers for given question from dataset for that i have used the pre-trained TAPAS model and tokenizer with Hugging face transformers in Python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 5, 4\n",
    "sb.set(style=\"white\")\n",
    "sb.set(style=\"whitegrid\", color_codes=True)\n",
    "plt.rc(\"font\", size=14)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Read the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0                       Player       Span  Mat Inns  NO   Runs  \\\n0             0         SR Tendulkar (INDIA)  1989-2012  463  452  41  18426   \n1             1  KC Sangakkara (Asia/ICC/SL)  2000-2015  404  380  41  14234   \n2             2         RT Ponting (AUS/ICC)  1995-2012  375  365  39  13704   \n3             3      ST Jayasuriya (Asia/SL)  1989-2011  445  433  18  13430   \n4             4   DPMD Jayawardene (Asia/SL)  1998-2015  448  418  39  12650   \n...         ...                          ...        ...  ...  ...  ..    ...   \n2495         45              ZS Ansari (ENG)  2015-2015    1    -   -      -   \n2496         46         Ariful Haque (BDESH)  2018-2018    1    -   -      -   \n2497         47           Ashfaq Ahmed (PAK)  1994-1994    3    -   -      -   \n2498         48               MD Bailey (NZ)  1998-1998    1    -   -      -   \n2499         49               GR Beard (AUS)  1981-1981    2    -   -      -   \n\n        HS    Ave     BF     SR 100  50   0 Unnamed: 13  \n0     200*  44.83  21367  86.23  49  96  20         nan  \n1      169  41.98  18048  78.86  25  93  15         nan  \n2      164  42.03  17046  80.39  30  82  20         nan  \n3      189  32.36  14725   91.2  28  68  34         nan  \n4      144  33.37  16020  78.96  19  77  28         nan  \n...    ...    ...    ...    ...  ..  ..  ..         ...  \n2495     -      -      -      -   -   -   -         nan  \n2496     -      -      -      -   -   -   -         nan  \n2497     -      -      -      -   -   -   -         nan  \n2498     -      -      -      -   -   -   -         nan  \n2499     -      -      -      -   -   -   -         nan  \n\n[2500 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Player</th>\n      <th>Span</th>\n      <th>Mat</th>\n      <th>Inns</th>\n      <th>NO</th>\n      <th>Runs</th>\n      <th>HS</th>\n      <th>Ave</th>\n      <th>BF</th>\n      <th>SR</th>\n      <th>100</th>\n      <th>50</th>\n      <th>0</th>\n      <th>Unnamed: 13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>SR Tendulkar (INDIA)</td>\n      <td>1989-2012</td>\n      <td>463</td>\n      <td>452</td>\n      <td>41</td>\n      <td>18426</td>\n      <td>200*</td>\n      <td>44.83</td>\n      <td>21367</td>\n      <td>86.23</td>\n      <td>49</td>\n      <td>96</td>\n      <td>20</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>KC Sangakkara (Asia/ICC/SL)</td>\n      <td>2000-2015</td>\n      <td>404</td>\n      <td>380</td>\n      <td>41</td>\n      <td>14234</td>\n      <td>169</td>\n      <td>41.98</td>\n      <td>18048</td>\n      <td>78.86</td>\n      <td>25</td>\n      <td>93</td>\n      <td>15</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT Ponting (AUS/ICC)</td>\n      <td>1995-2012</td>\n      <td>375</td>\n      <td>365</td>\n      <td>39</td>\n      <td>13704</td>\n      <td>164</td>\n      <td>42.03</td>\n      <td>17046</td>\n      <td>80.39</td>\n      <td>30</td>\n      <td>82</td>\n      <td>20</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>ST Jayasuriya (Asia/SL)</td>\n      <td>1989-2011</td>\n      <td>445</td>\n      <td>433</td>\n      <td>18</td>\n      <td>13430</td>\n      <td>189</td>\n      <td>32.36</td>\n      <td>14725</td>\n      <td>91.2</td>\n      <td>28</td>\n      <td>68</td>\n      <td>34</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>DPMD Jayawardene (Asia/SL)</td>\n      <td>1998-2015</td>\n      <td>448</td>\n      <td>418</td>\n      <td>39</td>\n      <td>12650</td>\n      <td>144</td>\n      <td>33.37</td>\n      <td>16020</td>\n      <td>78.96</td>\n      <td>19</td>\n      <td>77</td>\n      <td>28</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>45</td>\n      <td>ZS Ansari (ENG)</td>\n      <td>2015-2015</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>46</td>\n      <td>Ariful Haque (BDESH)</td>\n      <td>2018-2018</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>47</td>\n      <td>Ashfaq Ahmed (PAK)</td>\n      <td>1994-1994</td>\n      <td>3</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>48</td>\n      <td>MD Bailey (NZ)</td>\n      <td>1998-1998</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>49</td>\n      <td>GR Beard (AUS)</td>\n      <td>1981-1981</td>\n      <td>2</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = \"/Users/chalana/Desktop/Question generator/Question_Generator/ODI data.csv\"\n",
    "table  = pd.read_csv(address)\n",
    "\n",
    "table = table.astype(str)\n",
    "table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 15)\n",
      "Index(['Unnamed: 0', 'Player', 'Span', 'Mat', 'Inns', 'NO', 'Runs', 'HS',\n",
      "       'Ave', 'BF', 'SR', '100', '50', '0', 'Unnamed: 13'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(table.shape)\n",
    "print(table.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Checking for missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   2500 non-null   object\n",
      " 1   Player       2500 non-null   object\n",
      " 2   Span         2500 non-null   object\n",
      " 3   Mat          2500 non-null   object\n",
      " 4   Inns         2500 non-null   object\n",
      " 5   NO           2500 non-null   object\n",
      " 6   Runs         2500 non-null   object\n",
      " 7   HS           2500 non-null   object\n",
      " 8   Ave          2500 non-null   object\n",
      " 9   BF           2500 non-null   object\n",
      " 10  SR           2500 non-null   object\n",
      " 11  100          2500 non-null   object\n",
      " 12  50           2500 non-null   object\n",
      " 13  0            2500 non-null   object\n",
      " 14  Unnamed: 13  2500 non-null   object\n",
      "dtypes: object(15)\n",
      "memory usage: 293.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(table.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0     0\nPlayer         0\nSpan           0\nMat            0\nInns           0\nNO             0\nRuns           0\nHS             0\nAve            0\nBF             0\nSR             0\n100            0\n50             0\n0              0\nUnnamed: 13    0\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after renaming the unnamed column:\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Pos                       Player       Span  Mat Inns  NO   Runs    HS  \\\n0      0         SR Tendulkar (INDIA)  1989-2012  463  452  41  18426  200*   \n1      1  KC Sangakkara (Asia/ICC/SL)  2000-2015  404  380  41  14234   169   \n2      2         RT Ponting (AUS/ICC)  1995-2012  375  365  39  13704   164   \n3      3      ST Jayasuriya (Asia/SL)  1989-2011  445  433  18  13430   189   \n4      4   DPMD Jayawardene (Asia/SL)  1998-2015  448  418  39  12650   144   \n...   ..                          ...        ...  ...  ...  ..    ...   ...   \n2495  45              ZS Ansari (ENG)  2015-2015    1    -   -      -     -   \n2496  46         Ariful Haque (BDESH)  2018-2018    1    -   -      -     -   \n2497  47           Ashfaq Ahmed (PAK)  1994-1994    3    -   -      -     -   \n2498  48               MD Bailey (NZ)  1998-1998    1    -   -      -     -   \n2499  49               GR Beard (AUS)  1981-1981    2    -   -      -     -   \n\n        Ave     BF     SR 100  50   0 Unnamed: 13  \n0     44.83  21367  86.23  49  96  20         nan  \n1     41.98  18048  78.86  25  93  15         nan  \n2     42.03  17046  80.39  30  82  20         nan  \n3     32.36  14725   91.2  28  68  34         nan  \n4     33.37  16020  78.96  19  77  28         nan  \n...     ...    ...    ...  ..  ..  ..         ...  \n2495      -      -      -   -   -   -         nan  \n2496      -      -      -   -   -   -         nan  \n2497      -      -      -   -   -   -         nan  \n2498      -      -      -   -   -   -         nan  \n2499      -      -      -   -   -   -         nan  \n\n[2500 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pos</th>\n      <th>Player</th>\n      <th>Span</th>\n      <th>Mat</th>\n      <th>Inns</th>\n      <th>NO</th>\n      <th>Runs</th>\n      <th>HS</th>\n      <th>Ave</th>\n      <th>BF</th>\n      <th>SR</th>\n      <th>100</th>\n      <th>50</th>\n      <th>0</th>\n      <th>Unnamed: 13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>SR Tendulkar (INDIA)</td>\n      <td>1989-2012</td>\n      <td>463</td>\n      <td>452</td>\n      <td>41</td>\n      <td>18426</td>\n      <td>200*</td>\n      <td>44.83</td>\n      <td>21367</td>\n      <td>86.23</td>\n      <td>49</td>\n      <td>96</td>\n      <td>20</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>KC Sangakkara (Asia/ICC/SL)</td>\n      <td>2000-2015</td>\n      <td>404</td>\n      <td>380</td>\n      <td>41</td>\n      <td>14234</td>\n      <td>169</td>\n      <td>41.98</td>\n      <td>18048</td>\n      <td>78.86</td>\n      <td>25</td>\n      <td>93</td>\n      <td>15</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT Ponting (AUS/ICC)</td>\n      <td>1995-2012</td>\n      <td>375</td>\n      <td>365</td>\n      <td>39</td>\n      <td>13704</td>\n      <td>164</td>\n      <td>42.03</td>\n      <td>17046</td>\n      <td>80.39</td>\n      <td>30</td>\n      <td>82</td>\n      <td>20</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>ST Jayasuriya (Asia/SL)</td>\n      <td>1989-2011</td>\n      <td>445</td>\n      <td>433</td>\n      <td>18</td>\n      <td>13430</td>\n      <td>189</td>\n      <td>32.36</td>\n      <td>14725</td>\n      <td>91.2</td>\n      <td>28</td>\n      <td>68</td>\n      <td>34</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>DPMD Jayawardene (Asia/SL)</td>\n      <td>1998-2015</td>\n      <td>448</td>\n      <td>418</td>\n      <td>39</td>\n      <td>12650</td>\n      <td>144</td>\n      <td>33.37</td>\n      <td>16020</td>\n      <td>78.96</td>\n      <td>19</td>\n      <td>77</td>\n      <td>28</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>45</td>\n      <td>ZS Ansari (ENG)</td>\n      <td>2015-2015</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>46</td>\n      <td>Ariful Haque (BDESH)</td>\n      <td>2018-2018</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>47</td>\n      <td>Ashfaq Ahmed (PAK)</td>\n      <td>1994-1994</td>\n      <td>3</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>48</td>\n      <td>MD Bailey (NZ)</td>\n      <td>1998-1998</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>49</td>\n      <td>GR Beard (AUS)</td>\n      <td>1981-1981</td>\n      <td>2</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the unnamed column\n",
    "table.rename(columns={table.columns[0]: 'Pos'}, inplace=True)\n",
    "\n",
    "print(\"DataFrame after renaming the unnamed column:\")\n",
    "table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping column 'Unnamed: 13':\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Pos                       Player       Span  Mat Inns  NO   Runs    HS  \\\n0      0         SR Tendulkar (INDIA)  1989-2012  463  452  41  18426  200*   \n1      1  KC Sangakkara (Asia/ICC/SL)  2000-2015  404  380  41  14234   169   \n2      2         RT Ponting (AUS/ICC)  1995-2012  375  365  39  13704   164   \n3      3      ST Jayasuriya (Asia/SL)  1989-2011  445  433  18  13430   189   \n4      4   DPMD Jayawardene (Asia/SL)  1998-2015  448  418  39  12650   144   \n...   ..                          ...        ...  ...  ...  ..    ...   ...   \n2495  45              ZS Ansari (ENG)  2015-2015    1    -   -      -     -   \n2496  46         Ariful Haque (BDESH)  2018-2018    1    -   -      -     -   \n2497  47           Ashfaq Ahmed (PAK)  1994-1994    3    -   -      -     -   \n2498  48               MD Bailey (NZ)  1998-1998    1    -   -      -     -   \n2499  49               GR Beard (AUS)  1981-1981    2    -   -      -     -   \n\n        Ave     BF     SR 100  50   0  \n0     44.83  21367  86.23  49  96  20  \n1     41.98  18048  78.86  25  93  15  \n2     42.03  17046  80.39  30  82  20  \n3     32.36  14725   91.2  28  68  34  \n4     33.37  16020  78.96  19  77  28  \n...     ...    ...    ...  ..  ..  ..  \n2495      -      -      -   -   -   -  \n2496      -      -      -   -   -   -  \n2497      -      -      -   -   -   -  \n2498      -      -      -   -   -   -  \n2499      -      -      -   -   -   -  \n\n[2500 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pos</th>\n      <th>Player</th>\n      <th>Span</th>\n      <th>Mat</th>\n      <th>Inns</th>\n      <th>NO</th>\n      <th>Runs</th>\n      <th>HS</th>\n      <th>Ave</th>\n      <th>BF</th>\n      <th>SR</th>\n      <th>100</th>\n      <th>50</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>SR Tendulkar (INDIA)</td>\n      <td>1989-2012</td>\n      <td>463</td>\n      <td>452</td>\n      <td>41</td>\n      <td>18426</td>\n      <td>200*</td>\n      <td>44.83</td>\n      <td>21367</td>\n      <td>86.23</td>\n      <td>49</td>\n      <td>96</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>KC Sangakkara (Asia/ICC/SL)</td>\n      <td>2000-2015</td>\n      <td>404</td>\n      <td>380</td>\n      <td>41</td>\n      <td>14234</td>\n      <td>169</td>\n      <td>41.98</td>\n      <td>18048</td>\n      <td>78.86</td>\n      <td>25</td>\n      <td>93</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>RT Ponting (AUS/ICC)</td>\n      <td>1995-2012</td>\n      <td>375</td>\n      <td>365</td>\n      <td>39</td>\n      <td>13704</td>\n      <td>164</td>\n      <td>42.03</td>\n      <td>17046</td>\n      <td>80.39</td>\n      <td>30</td>\n      <td>82</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>ST Jayasuriya (Asia/SL)</td>\n      <td>1989-2011</td>\n      <td>445</td>\n      <td>433</td>\n      <td>18</td>\n      <td>13430</td>\n      <td>189</td>\n      <td>32.36</td>\n      <td>14725</td>\n      <td>91.2</td>\n      <td>28</td>\n      <td>68</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>DPMD Jayawardene (Asia/SL)</td>\n      <td>1998-2015</td>\n      <td>448</td>\n      <td>418</td>\n      <td>39</td>\n      <td>12650</td>\n      <td>144</td>\n      <td>33.37</td>\n      <td>16020</td>\n      <td>78.96</td>\n      <td>19</td>\n      <td>77</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>45</td>\n      <td>ZS Ansari (ENG)</td>\n      <td>2015-2015</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>46</td>\n      <td>Ariful Haque (BDESH)</td>\n      <td>2018-2018</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>47</td>\n      <td>Ashfaq Ahmed (PAK)</td>\n      <td>1994-1994</td>\n      <td>3</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>48</td>\n      <td>MD Bailey (NZ)</td>\n      <td>1998-1998</td>\n      <td>1</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>49</td>\n      <td>GR Beard (AUS)</td>\n      <td>1981-1981</td>\n      <td>2</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n<p>2500 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_drop = 'Unnamed: 13'\n",
    "table_new = table.drop(column_to_drop, axis=1)\n",
    "\n",
    "print(\"\\nDataFrame after dropping column '{}':\".format(column_to_drop))\n",
    "table_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# query = \"Who has scored the highest runs?\"\n",
    "# print(tqa(table=table,query=query)[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data = table_new.astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Question :\n",
      "\n",
      "Who has scored the highest runs\n",
      "What is the average number of Runs?\n",
      "what is the Tendulkar HS?\n"
     ]
    }
   ],
   "source": [
    "# Define the questions\n",
    "queries = [\"Who has scored the highest runs\",\n",
    "           \"What is the average number of Runs?\",\n",
    "           \"what is the Tendulkar HS?\"]\n",
    "\n",
    "print(\"Suggested Question :\\n\")\n",
    "\n",
    "for i in queries:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### loads the pre-trained TAPAS model and tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    # Load pretrained tokenizer: TAPAS finetuned on WikiTable Questions\n",
    "    tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "    # Load pretrained model: TAPAS finetuned on WikiTable Questions\n",
    "    model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "\n",
    "    return tokenizer, model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Generating Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def generate_predictions(inputs, model, tokenizer):\n",
    "    \"\"\"\n",
    "      Generate predictions for some tokenized input.\n",
    "    \"\"\"\n",
    "    # Generate model results\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Convert logit outputs into predictions for table cells and aggregation operators\n",
    "    predicted_table_cell_coords, predicted_aggregation_operators = tokenizer.convert_logits_to_predictions(\n",
    "        inputs,\n",
    "        outputs.logits.detach(),\n",
    "        outputs.logits_aggregation.detach()\n",
    "    )\n",
    "\n",
    "    # Return values\n",
    "    return predicted_table_cell_coords, predicted_aggregation_operators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Postprocessing Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def postprocess_predictions(predicted_aggregation_operators, predicted_table_cell_coords, table):\n",
    "    \"\"\"\n",
    "      Compute the predicted operation and nicely structure the answers.\n",
    "    \"\"\"\n",
    "    # Process predicted aggregation operators\n",
    "    aggregation_operators = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3:\"COUNT\"}\n",
    "    aggregation_predictions_string = [aggregation_operators[x] for x in predicted_aggregation_operators]\n",
    "\n",
    "    # Process predicted table cell coordinates\n",
    "    answers = []\n",
    "    for coordinates in predicted_table_cell_coords:\n",
    "        if len(coordinates) == 1:\n",
    "            # 1 cell\n",
    "            answers.append(table.iat[coordinates[0]])\n",
    "        else:\n",
    "            # > 1 cell\n",
    "            cell_values = []\n",
    "            for coordinate in coordinates:\n",
    "                cell_values.append(table.iat[coordinate])\n",
    "            answers.append(\", \".join(cell_values))\n",
    "\n",
    "    # Return values\n",
    "    return aggregation_predictions_string, answers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Displaying Answers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def show_answers(queries, answers, aggregation_predictions_string):\n",
    "    \"\"\"\n",
    "      Visualize the postprocessed answers.\n",
    "    \"\"\"\n",
    "    for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n",
    "        print(\"\\n\" + query)\n",
    "        if predicted_agg == \"NONE\":\n",
    "            print(\"Predicted answer: \" + answer)\n",
    "        else:\n",
    "            print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Processing in Batches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def process_batch(table, queries, batch_size, model, tokenizer):\n",
    "    num_samples = len(table)\n",
    "    #for i in range(0, num_samples, batch_size):\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_table = table.iloc[i:i+batch_size]\n",
    "        inputs = tokenizer(table=batch_table, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
    "        predicted_table_cell_coords, predicted_aggregation_operators = generate_predictions(inputs, model, tokenizer)\n",
    "        aggregation_predictions_string, answers = postprocess_predictions(predicted_aggregation_operators, predicted_table_cell_coords, batch_table)\n",
    "        show_answers(queries, answers, aggregation_predictions_string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Running TAPAS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def run_tapas():\n",
    "    tokenizer, model = load_model_and_tokenizer()\n",
    "\n",
    "    # Define the table\n",
    "    table = data\n",
    "\n",
    "    batch_size = 2  # Set the batch size\n",
    "\n",
    "    process_batch(table, queries, batch_size, model, tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Who has scored the highest runs\n",
      "Predicted answer: SR Tendulkar (INDIA)\n",
      "\n",
      "What is the average number of Runs?\n",
      "Predicted answer: AVERAGE > 18426, 14234\n",
      "\n",
      "what is the Tendulkar HS?\n",
      "Predicted answer: 200*\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "iloc cannot enlarge its target object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mrun_tapas\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 9\u001B[0m, in \u001B[0;36mrun_tapas\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m table \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m      7\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m  \u001B[38;5;66;03m# Set the batch size\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[43mprocess_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 6\u001B[0m, in \u001B[0;36mprocess_batch\u001B[0;34m(table, queries, batch_size, model, tokenizer)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, num_samples, batch_size):\n\u001B[1;32m      5\u001B[0m     batch_table \u001B[38;5;241m=\u001B[39m table\u001B[38;5;241m.\u001B[39miloc[i:i\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[0;32m----> 6\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqueries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_length\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     predicted_table_cell_coords, predicted_aggregation_operators \u001B[38;5;241m=\u001B[39m generate_predictions(inputs, model, tokenizer)\n\u001B[1;32m      8\u001B[0m     aggregation_predictions_string, answers \u001B[38;5;241m=\u001B[39m postprocess_predictions(predicted_aggregation_operators, predicted_table_cell_coords, batch_table)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py:650\u001B[0m, in \u001B[0;36mTapasTokenizer.__call__\u001B[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    647\u001B[0m is_batched \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(queries, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m))\n\u001B[1;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_batched:\n\u001B[0;32m--> 650\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    651\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[43m        \u001B[49m\u001B[43mqueries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[43m        \u001B[49m\u001B[43manswer_coordinates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_coordinates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    654\u001B[0m \u001B[43m        \u001B[49m\u001B[43manswer_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    655\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    656\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    657\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    658\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    659\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    661\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    662\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    663\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    666\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    671\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[1;32m    672\u001B[0m         table\u001B[38;5;241m=\u001B[39mtable,\n\u001B[1;32m    673\u001B[0m         query\u001B[38;5;241m=\u001B[39mqueries,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    689\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    690\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py:768\u001B[0m, in \u001B[0;36mTapasTokenizer.batch_encode_plus\u001B[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_offsets_mapping:\n\u001B[1;32m    762\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    763\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    764\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    765\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransformers.PreTrainedTokenizerFast.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    766\u001B[0m     )\n\u001B[0;32m--> 768\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    769\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqueries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer_coordinates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_coordinates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    772\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    773\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    774\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    775\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    776\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    777\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    778\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    780\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    782\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    786\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    787\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py:835\u001B[0m, in \u001B[0;36mTapasTokenizer._batch_encode_plus\u001B[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    832\u001B[0m     queries[idx] \u001B[38;5;241m=\u001B[39m query\n\u001B[1;32m    833\u001B[0m     queries_tokens\u001B[38;5;241m.\u001B[39mappend(query_tokens)\n\u001B[0;32m--> 835\u001B[0m batch_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_prepare_for_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqueries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenized_table\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtable_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqueries_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqueries_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    840\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer_coordinates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_coordinates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprepend_batch_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m BatchEncoding(batch_outputs)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py:890\u001B[0m, in \u001B[0;36mTapasTokenizer._batch_prepare_for_model\u001B[0;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001B[0m\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, example \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(raw_queries, queries_tokens, answer_coordinates, answer_text)):\n\u001B[1;32m    889\u001B[0m     raw_query, query_tokens, answer_coords, answer_txt \u001B[38;5;241m=\u001B[39m example\n\u001B[0;32m--> 890\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_for_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_table\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenized_table\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenized_table\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43manswer_coordinates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_coords\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43manswer_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_txt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    898\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPaddingStrategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDO_NOT_PAD\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# we pad in batch afterwards\u001B[39;49;00m\n\u001B[1;32m    899\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# we pad in batch afterwards\u001B[39;49;00m\n\u001B[1;32m    902\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# we pad in batch afterwards\u001B[39;49;00m\n\u001B[1;32m    903\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# We convert the whole batch to tensors at the end\u001B[39;49;00m\n\u001B[1;32m    907\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprepend_batch_axis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprev_answer_coordinates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_coordinates\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprev_answer_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manswer_text\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    913\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    914\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m batch_outputs:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py:1229\u001B[0m, in \u001B[0;36mTapasTokenizer.prepare_for_model\u001B[0;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001B[0m\n\u001B[1;32m   1223\u001B[0m     prev_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_answer_ids(\n\u001B[1;32m   1224\u001B[0m         column_ids, row_ids, table_data, prev_answer_text, prev_answer_coordinates\n\u001B[1;32m   1225\u001B[0m     )\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;66;03m# FIRST: parse both the table and question in terms of numeric values\u001B[39;00m\n\u001B[0;32m-> 1229\u001B[0m raw_table \u001B[38;5;241m=\u001B[39m \u001B[43madd_numeric_table_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1230\u001B[0m raw_query \u001B[38;5;241m=\u001B[39m add_numeric_values_to_question(raw_query)\n\u001B[1;32m   1232\u001B[0m \u001B[38;5;66;03m# SECOND: add numeric-related features (and not parse them in these functions):\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py:2826\u001B[0m, in \u001B[0;36madd_numeric_table_values\u001B[0;34m(table, min_consolidation_fraction, debug_info)\u001B[0m\n\u001B[1;32m   2824\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row_index, row \u001B[38;5;129;01min\u001B[39;00m table\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m   2825\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m col_index, cell \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(row):\n\u001B[0;32m-> 2826\u001B[0m         table\u001B[38;5;241m.\u001B[39miloc[row_index, col_index] \u001B[38;5;241m=\u001B[39m Cell(text\u001B[38;5;241m=\u001B[39mcell)\n\u001B[1;32m   2828\u001B[0m \u001B[38;5;66;03m# Third, add numeric_value attributes to these Cell objects\u001B[39;00m\n\u001B[1;32m   2829\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col_index, column \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(table\u001B[38;5;241m.\u001B[39mcolumns):\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/pandas/core/indexing.py:846\u001B[0m, in \u001B[0;36m_LocationIndexer.__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m    844\u001B[0m     key \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m    845\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_setitem_indexer(key)\n\u001B[0;32m--> 846\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_has_valid_setitem_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    848\u001B[0m iloc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39miloc\n\u001B[1;32m    849\u001B[0m iloc\u001B[38;5;241m.\u001B[39m_setitem_with_indexer(indexer, value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/newConda/lib/python3.8/site-packages/pandas/core/indexing.py:1550\u001B[0m, in \u001B[0;36m_iLocIndexer._has_valid_setitem_indexer\u001B[0;34m(self, indexer)\u001B[0m\n\u001B[1;32m   1548\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_integer(i):\n\u001B[1;32m   1549\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ax):\n\u001B[0;32m-> 1550\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc cannot enlarge its target object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(i, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m   1552\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc cannot enlarge its target object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: iloc cannot enlarge its target object"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_tapas()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlu = pipeline(\"table-question-answering\", model=\"google/tapas-base-finetuned-wtq\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_question = input(\"Ask a question or type 'exit' to quit: \")\n",
    "\n",
    "    if user_question.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Perform NLU on the question\n",
    "    #answer = nlu(context=table_new.to_string(), question=user_question)\n",
    "    answer = nlu(table=table_new, query=user_question)\n",
    "\n",
    "    print(\"Answer:\", answer['answer'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
